# Handle prompts being passed to LLMs (Maybe API, definitely local)
